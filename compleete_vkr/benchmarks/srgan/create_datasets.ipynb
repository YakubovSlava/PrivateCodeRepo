{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import torch\n",
    "from torch import nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "for path in ['cats_orig', 'cats_small', 'cats_bicubic', 'cats_nearest', 'cats_refactored']:\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "for path in ['dogs_orig', 'dogs_small', 'dogs_bicubic', 'dogs_nearest', 'dogs_refactored']:\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 64,\n",
    "            out_channels = 64,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1,\n",
    "            padding_mode='reflect'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               stride = stride,\n",
    "                               padding= padding,\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.PReLU(num_parameters=out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = in_channels,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               stride = stride,\n",
    "                               padding= padding,\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = out + x\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class GeneratorUpsample(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 64,\n",
    "            upsample_value = 2,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsample_value = upsample_value\n",
    "        self.in_channels = in_channels\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "                              out_channels=self.in_channels*upsample_value*upsample_value,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              stride = self.stride)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor=upsample_value)\n",
    "        self.activation = nn.PReLU(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 3,\n",
    "            out_channels = 3,\n",
    "            hidden_channels = 64,\n",
    "            num_res_blocks = 16\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.initial_conv = nn.Conv2d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.hidden_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 9,\n",
    "            padding = 4\n",
    "        )\n",
    "        self.activation = nn.PReLU(self.hidden_channels)\n",
    "        self.residual_blocks = nn.Sequential(*[ResidualBlock() for _ in range(num_res_blocks)])\n",
    "        self.middle_conv = nn.Conv2d(\n",
    "            in_channels = self.hidden_channels,\n",
    "            out_channels = self.hidden_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(self.hidden_channels)\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            in_channels = self.hidden_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 9,\n",
    "            padding_mode='reflect',\n",
    "            padding = 4\n",
    "        )\n",
    "        self.up1 = GeneratorUpsample()\n",
    "        self.up2 = GeneratorUpsample()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.activation(x)\n",
    "        out = self.residual_blocks(x)\n",
    "        out = self.middle_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = out + x\n",
    "        out = self.up1(out)\n",
    "        out = self.up2(out)\n",
    "        out = self.final_conv(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "state = torch.load('srgan_gen_430.pth', map_location=device)['state_dict']\n",
    "model = Generator().to(device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print('model loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "path_dogs = '../../dataset/test_set/test_set/dogs'\n",
    "path_cats = '../../dataset/test_set/test_set/cats'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "img_path = os.path.join(path_dogs, os.listdir(path_dogs)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "prep = A.Compose(\n",
    "            [\n",
    "                A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "                ToTensorV2()\n",
    "            ]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 13.91it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(path_dogs)[:10]):\n",
    "    if i != '_DS_Store':\n",
    "        img_path = os.path.join(path_dogs, i)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "\n",
    "        image_shape = np.asarray(image).shape\n",
    "\n",
    "        image_small = A.resize(np.asarray(image), image_shape[0]//4, image_shape[1]//4, interpolation=Image.Resampling.BICUBIC)\n",
    "        image_bicubic = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BICUBIC)\n",
    "        image_nearest = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BILINEAR)\n",
    "\n",
    "        format_image = prep(image = image_small)['image'].to(device)\n",
    "        with torch.no_grad():\n",
    "            res_image = model(format_image.unsqueeze(0)).detach().cpu()\n",
    "        save_image((res_image).abs(), os.path.join('dogs_refactored/', i))\n",
    "\n",
    "        Image.fromarray(image_small).save(os.path.join('dogs_small/', i))\n",
    "        Image.fromarray(image_bicubic).save(os.path.join('dogs_bicubic/', i))\n",
    "        Image.fromarray(image_nearest).save(os.path.join('dogs_nearest/', i))\n",
    "        image.save(os.path.join('dogs_orig/', i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "124"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.asarray(image).shape[0]//4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yakub\\AppData\\Local\\Temp\\ipykernel_20136\\4095616802.py:1: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  A.resize((image_shape[0]//4, image_shape[1]//4), interpolation=Image.BICUBIC)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [24]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mA\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_shape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mimage_shape\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minterpolation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mImage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBICUBIC\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\mlp\\MachineLearning\\venv\\lib\\site-packages\\albumentations\\augmentations\\functional.py:69\u001B[0m, in \u001B[0;36mpreserve_channel_dim.<locals>.wrapped_function\u001B[1;34m(img, *args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m     68\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_function\u001B[39m(img, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 69\u001B[0m     shape \u001B[38;5;241m=\u001B[39m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\n\u001B[0;32m     70\u001B[0m     result \u001B[38;5;241m=\u001B[39m func(img, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     71\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(shape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m3\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m shape[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(result\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "A.resize(image_shape[0]//4, image_shape[1]//4, interpolation=Image.BICUBIC)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yakub\\AppData\\Local\\Temp\\ipykernel_19860\\120230055.py:1: DeprecationWarning: NEAREST is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.NEAREST or Dither.NONE instead.\n",
      "  Image.NEAREST\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.NEAREST"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}