{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import torch\n",
    "from torch import nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import numpy as np\n",
    "from torchvision.utils import save_image\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "for path in ['cats_orig', 'cats_small', 'cats_bicubic', 'cats_bilinear', 'cats_refactored']:\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "for path in ['dogs_orig', 'dogs_small', 'dogs_bicubic', 'dogs_bilinear', 'dogs_refactored']:\n",
    "    if not os.path.isdir(path):\n",
    "        os.mkdir(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 64,\n",
    "            out_channels = 64,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1,\n",
    "            padding_mode='reflect'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               stride = stride,\n",
    "                               padding= padding,\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.PReLU(num_parameters=out_channels)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = in_channels,\n",
    "                               out_channels = out_channels,\n",
    "                               kernel_size = kernel_size,\n",
    "                               stride = stride,\n",
    "                               padding= padding,\n",
    "                               bias=False)\n",
    "\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.activation(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = out + x\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class GeneratorUpsample(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 64,\n",
    "            upsample_value = 2,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.upsample_value = upsample_value\n",
    "        self.in_channels = in_channels\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.in_channels,\n",
    "                              out_channels=self.in_channels*upsample_value*upsample_value,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              stride = self.stride)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor=upsample_value)\n",
    "        self.activation = nn.PReLU(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels = 3,\n",
    "            out_channels = 3,\n",
    "            hidden_channels = 64,\n",
    "            num_res_blocks = 16\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.num_res_blocks = num_res_blocks\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "        self.initial_conv = nn.Conv2d(\n",
    "            in_channels = self.in_channels,\n",
    "            out_channels = self.hidden_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 9,\n",
    "            padding = 4\n",
    "        )\n",
    "        self.activation = nn.PReLU(self.hidden_channels)\n",
    "        self.residual_blocks = nn.Sequential(*[ResidualBlock() for _ in range(num_res_blocks)])\n",
    "        self.middle_conv = nn.Conv2d(\n",
    "            in_channels = self.hidden_channels,\n",
    "            out_channels = self.hidden_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 3,\n",
    "            padding = 1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(self.hidden_channels)\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            in_channels = self.hidden_channels,\n",
    "            out_channels = self.out_channels,\n",
    "            stride = 1,\n",
    "            kernel_size = 9,\n",
    "            padding_mode='reflect',\n",
    "            padding = 4\n",
    "        )\n",
    "        self.up1 = GeneratorUpsample()\n",
    "        self.up2 = GeneratorUpsample()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.initial_conv(x)\n",
    "        x = self.activation(x)\n",
    "        out = self.residual_blocks(x)\n",
    "        out = self.middle_conv(out)\n",
    "        out = self.bn(out)\n",
    "        out = out + x\n",
    "        out = self.up1(out)\n",
    "        out = self.up2(out)\n",
    "        out = self.final_conv(out)\n",
    "        return out"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model loaded\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "state = torch.load('srresnet_80.pth', map_location=device)['state_dict']\n",
    "model = Generator().to(device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "print('model loaded')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "path_dogs = '../../dataset/test_set/test_set/dogs'\n",
    "path_cats = '../../dataset/test_set/test_set/cats'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "img_path = os.path.join(path_dogs, os.listdir(path_dogs)[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "prep = A.Compose(\n",
    "            [\n",
    "                A.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "                ToTensorV2()\n",
    "            ]\n",
    "        )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [00:41<00:00, 24.51it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(path_dogs)):\n",
    "    if i != '_DS_Store':\n",
    "        img_path = os.path.join(path_dogs, i)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "\n",
    "        image_shape = np.asarray(image).shape\n",
    "\n",
    "        image_small = A.resize(np.asarray(image), image_shape[0]//4, image_shape[1]//4, interpolation=Image.Resampling.BICUBIC)\n",
    "        image_bicubic = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BICUBIC)\n",
    "        image_nearest = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BILINEAR)\n",
    "\n",
    "        format_image = prep(image = image_small)['image'].to(device)\n",
    "        with torch.no_grad():\n",
    "            res_image = model(format_image.unsqueeze(0)).detach().cpu()\n",
    "        save_image((res_image).abs(), os.path.join('dogs_refactored/', i))\n",
    "\n",
    "        Image.fromarray(image_small).save(os.path.join('dogs_small/', i))\n",
    "        Image.fromarray(image_bicubic).resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('dogs_bicubic/', i))\n",
    "        Image.fromarray(image_nearest).resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('dogs_bilinear/', i))\n",
    "        image.resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('dogs_orig/', i))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1011/1011 [00:41<00:00, 24.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(os.listdir(path_cats)):\n",
    "    if i != '_DS_Store':\n",
    "        img_path = os.path.join(path_cats, i)\n",
    "        image = Image.open(img_path)\n",
    "\n",
    "\n",
    "        image_shape = np.asarray(image).shape\n",
    "\n",
    "        image_small = A.resize(np.asarray(image), image_shape[0]//4, image_shape[1]//4, interpolation=Image.Resampling.BICUBIC)\n",
    "        image_bicubic = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BICUBIC)\n",
    "        image_nearest = A.resize(np.asarray(image_small), image_shape[0], image_shape[1], interpolation=Image.Resampling.BILINEAR)\n",
    "\n",
    "        format_image = prep(image = image_small)['image'].to(device)\n",
    "        with torch.no_grad():\n",
    "            res_image = model(format_image.unsqueeze(0)).detach().cpu()\n",
    "        save_image((res_image).abs(), os.path.join('cats_refactored/', i))\n",
    "\n",
    "        Image.fromarray(image_small).save(os.path.join('cats_small/', i))\n",
    "        Image.fromarray(image_bicubic).resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('cats_bicubic/', i))\n",
    "        Image.fromarray(image_nearest).resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('cats_bilinear/', i))\n",
    "        image.resize((image_shape[1]//4*4, image_shape[0]//4*4)).save(os.path.join('cats_orig/', i))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}